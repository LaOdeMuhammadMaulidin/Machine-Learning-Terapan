# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13-e33Y1eF_tzwEx7rH0sGXcGePalA_dw
"""

import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

df = pd.read_csv('/content/stroke_risk_dataset_v2.csv')
df.head()

df.info()

hapus = ['stroke_risk_percentage']
df = df.drop(columns=hapus, errors='ignore')

df.isnull().sum()

df.dropna(inplace=True)
df.describe()

print(f'jumlah duplikat sebelum = {df.duplicated().sum()}')

df.drop_duplicates(inplace=True)

print(f'jumlah duplikat sesudah = {df.duplicated().sum()}')

print(f"\nUkuran Dataset: {df.shape[0]} baris, {df.shape[1]} kolom")

for col in ['gender']:
    if col in df.columns:
        print(f"\nNilai Unik di Kolom '{col}':")
        print(df[col].unique())

df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})

print("Mean setelah normalisasi:")
print(pd.DataFrame(df).mean())

print("\nStandar Deviasi setelah normalisasi:")
print(pd.DataFrame(df).std())

print("Distribusi Kelas Target:")
print(df['at_risk'].value_counts())

labels = df['at_risk']

# Remove the labels from the features
df = df.drop('at_risk', axis = 1)

# Saving feature names for later use
feature_list = list(df.columns)

train_features, test_features, train_labels, test_labels = train_test_split(df,
                                                                            labels,
                                                                            test_size = 0.20,
                                                                            random_state = 42)

train_features.shape, test_features.shape

test_features.dtypes

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

rfC = RandomForestClassifier(random_state = 0)
rfC.fit(train_features, train_labels)

predict = rfC.predict(test_features)

print(f"Akurasi: {accuracy_score(test_labels, predict)}")

rfC_100 = RandomForestClassifier(n_estimators = 100, random_state = 0)
rfC_100.fit(train_features, train_labels)

predict = rfC_100.predict(test_features)

print(f"Akurasi: {accuracy_score(test_labels, predict)}")

clf = RandomForestClassifier(n_estimators = 50, random_state = 0)
clf.fit(train_features, train_labels)

feature_scores = pd.Series(clf.feature_importances_, index=feature_list).sort_values(ascending=False)
feature_scores

sns.barplot(x=feature_scores, y=feature_scores.index)
plt.xlabel('Feature Importance Score')
plt.ylabel('Features')
plt.title("Visualizing Important Features")
plt.show()

cm = confusion_matrix(test_labels, predict)

# Visualisasi confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import classification_report

print(classification_report(test_labels, predict))